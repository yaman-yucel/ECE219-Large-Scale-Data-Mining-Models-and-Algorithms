{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b2af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#from ydata_profiling import ProfileReport\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error,make_scorer,r2_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafd65b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d05469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diamonds = pd.read_csv(\"diamonds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0c6732",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diamond = df_diamonds.drop(columns = \"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0880d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(df_diamond, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dec9ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_set.drop(columns = \"price\")\n",
    "train_labels = pd.DataFrame(train_set[\"price\"])\n",
    "\n",
    "test_features = test_set.drop(columns = \"price\")\n",
    "test_labels = pd.DataFrame(test_set[\"price\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c823964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline only cat\n",
    "num_attributes = [\"carat\",\"depth\",\"table\",\"x\",\"y\",\"z\"]\n",
    "cat_cut_level = [['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']] \n",
    "cat_color_level = [['J', 'I', 'H', 'G', 'F', 'E', 'D']]\n",
    "cat_clarity_level = [['I1', 'SI2', 'SI1', 'VS2','VS1', 'VVS2','VVS1', 'IF']]\n",
    "cat_attributes= [\"cut\",\"color\",\"clarity\"]\n",
    "\n",
    "full_pipeline_cat = ColumnTransformer(\n",
    "    transformers = [\n",
    "    (\"cat_cut\",     OrdinalEncoder(categories=cat_cut_level),[\"cut\"]),\n",
    "    (\"cat_color\",   OrdinalEncoder(categories=cat_color_level),[\"color\"]),\n",
    "    (\"cat_clarity\", OrdinalEncoder(categories=cat_clarity_level),[\"clarity\"])\n",
    "    ],\n",
    "    remainder = \"passthrough\"\n",
    ")\n",
    "    \n",
    "train_features_cat = full_pipeline_cat.fit_transform(train_features)\n",
    "test_features_cat = full_pipeline_cat.transform(test_features)\n",
    "\n",
    "if(full_pipeline_cat.sparse_output_):\n",
    "    train_features_cat = train_features_cat.toarray()\n",
    "    test_features_cat = test_features_cat.toarray()\n",
    "    \n",
    "#Make them dataframe\n",
    "df_train_features_cat = pd.DataFrame(train_features_cat, columns =  cat_attributes + num_attributes )\n",
    "df_test_features_cat = pd.DataFrame(test_features_cat, columns = cat_attributes + num_attributes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56c7710e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.01</td>\n",
       "      <td>58.1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8.23</td>\n",
       "      <td>8.19</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.57</td>\n",
       "      <td>6.49</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>62.5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.54</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>61.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>7.21</td>\n",
       "      <td>7.17</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>62.1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.32</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43147</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.05</td>\n",
       "      <td>62.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.48</td>\n",
       "      <td>6.51</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43148</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>61.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.01</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43149</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>60.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.46</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43150</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>62.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.13</td>\n",
       "      <td>6.03</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43151</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>60.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.79</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43152 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cut  color  clarity  carat  depth  table     x     y     z\n",
       "0      1.0    4.0      1.0   2.01   58.1   64.0  8.23  8.19  4.77\n",
       "1      2.0    5.0      1.0   1.01   60.0   60.0  6.57  6.49  3.92\n",
       "2      3.0    2.0      3.0   1.10   62.5   58.0  6.59  6.54  4.10\n",
       "3      1.0    5.0      1.0   1.50   61.5   65.0  7.21  7.17  4.42\n",
       "4      2.0    3.0      4.0   1.52   62.1   57.0  7.27  7.32  4.53\n",
       "...    ...    ...      ...    ...    ...    ...   ...   ...   ...\n",
       "43147  2.0    1.0      3.0   1.05   62.4   59.0  6.48  6.51  4.05\n",
       "43148  4.0    6.0      4.0   0.47   61.0   55.0  5.03  5.01  3.06\n",
       "43149  2.0    4.0      7.0   0.33   60.3   58.0  4.49  4.46  2.70\n",
       "43150  3.0    0.0      2.0   0.90   62.8   59.0  6.13  6.03  3.82\n",
       "43151  3.0    4.0      2.0   1.14   60.4   58.0  6.82  6.79  4.11\n",
       "\n",
       "[43152 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_features_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b6e197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline with standardscaler\n",
    "num_attributes = [\"carat\",\"depth\",\"table\",\"x\",\"y\",\"z\"]\n",
    "all_atributes =  cat_attributes + num_attributes\n",
    "\n",
    "num_pipeline_scaler = Pipeline([\n",
    "    ('std_scaler',StandardScaler()),\n",
    "])\n",
    "\n",
    "\n",
    "full_pipeline_scaler = ColumnTransformer(\n",
    "    transformers = [\n",
    "    (\"num\", num_pipeline_scaler, all_atributes),\n",
    "    ],\n",
    "    remainder = \"passthrough\"\n",
    ")\n",
    "    \n",
    "\n",
    "train_features_ss = full_pipeline_scaler.fit_transform(df_train_features_cat)\n",
    "test_features_ss = full_pipeline_scaler.transform(df_test_features_cat)\n",
    "\n",
    "if(full_pipeline_scaler.sparse_output_):\n",
    "    train_features_ss = train_features_ss.toarray()\n",
    "    test_features_ss = test_features_ss.toarray()\n",
    "    \n",
    "#Make them dataframe\n",
    "df_train_features_ss = pd.DataFrame(train_features_ss, columns = all_atributes)\n",
    "df_test_features_ss  = pd.DataFrame(test_features_ss, columns = all_atributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dac4ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.708965</td>\n",
       "      <td>0.347949</td>\n",
       "      <td>-1.246901</td>\n",
       "      <td>2.560056</td>\n",
       "      <td>-2.550748</td>\n",
       "      <td>2.933861</td>\n",
       "      <td>2.229450</td>\n",
       "      <td>2.138209</td>\n",
       "      <td>1.738207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.812192</td>\n",
       "      <td>0.936621</td>\n",
       "      <td>-1.246901</td>\n",
       "      <td>0.447392</td>\n",
       "      <td>-1.220426</td>\n",
       "      <td>1.139575</td>\n",
       "      <td>0.747550</td>\n",
       "      <td>0.656710</td>\n",
       "      <td>0.537733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.084582</td>\n",
       "      <td>-0.829396</td>\n",
       "      <td>-0.032134</td>\n",
       "      <td>0.637532</td>\n",
       "      <td>0.529996</td>\n",
       "      <td>0.242432</td>\n",
       "      <td>0.765404</td>\n",
       "      <td>0.700284</td>\n",
       "      <td>0.791951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.708965</td>\n",
       "      <td>0.936621</td>\n",
       "      <td>-1.246901</td>\n",
       "      <td>1.482597</td>\n",
       "      <td>-0.170173</td>\n",
       "      <td>3.382432</td>\n",
       "      <td>1.318885</td>\n",
       "      <td>1.249310</td>\n",
       "      <td>1.243894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.812192</td>\n",
       "      <td>-0.240724</td>\n",
       "      <td>0.575249</td>\n",
       "      <td>1.524851</td>\n",
       "      <td>0.249928</td>\n",
       "      <td>-0.206140</td>\n",
       "      <td>1.372448</td>\n",
       "      <td>1.380030</td>\n",
       "      <td>1.399249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43147</th>\n",
       "      <td>-0.812192</td>\n",
       "      <td>-1.418069</td>\n",
       "      <td>-0.032134</td>\n",
       "      <td>0.531899</td>\n",
       "      <td>0.459979</td>\n",
       "      <td>0.691003</td>\n",
       "      <td>0.667206</td>\n",
       "      <td>0.674140</td>\n",
       "      <td>0.721335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43148</th>\n",
       "      <td>0.981355</td>\n",
       "      <td>1.525294</td>\n",
       "      <td>0.575249</td>\n",
       "      <td>-0.693447</td>\n",
       "      <td>-0.520257</td>\n",
       "      <td>-1.103283</td>\n",
       "      <td>-0.627225</td>\n",
       "      <td>-0.633065</td>\n",
       "      <td>-0.676864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43149</th>\n",
       "      <td>-0.812192</td>\n",
       "      <td>0.347949</td>\n",
       "      <td>2.397399</td>\n",
       "      <td>-0.989219</td>\n",
       "      <td>-1.010376</td>\n",
       "      <td>0.242432</td>\n",
       "      <td>-1.109289</td>\n",
       "      <td>-1.112374</td>\n",
       "      <td>-1.185299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43150</th>\n",
       "      <td>0.084582</td>\n",
       "      <td>-2.006742</td>\n",
       "      <td>-0.639517</td>\n",
       "      <td>0.214999</td>\n",
       "      <td>0.740047</td>\n",
       "      <td>0.691003</td>\n",
       "      <td>0.354757</td>\n",
       "      <td>0.255834</td>\n",
       "      <td>0.396501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43151</th>\n",
       "      <td>0.084582</td>\n",
       "      <td>0.347949</td>\n",
       "      <td>-0.639517</td>\n",
       "      <td>0.722038</td>\n",
       "      <td>-0.940359</td>\n",
       "      <td>0.242432</td>\n",
       "      <td>0.970728</td>\n",
       "      <td>0.918151</td>\n",
       "      <td>0.806074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43152 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            cut     color   clarity     carat     depth     table         x  \\\n",
       "0     -1.708965  0.347949 -1.246901  2.560056 -2.550748  2.933861  2.229450   \n",
       "1     -0.812192  0.936621 -1.246901  0.447392 -1.220426  1.139575  0.747550   \n",
       "2      0.084582 -0.829396 -0.032134  0.637532  0.529996  0.242432  0.765404   \n",
       "3     -1.708965  0.936621 -1.246901  1.482597 -0.170173  3.382432  1.318885   \n",
       "4     -0.812192 -0.240724  0.575249  1.524851  0.249928 -0.206140  1.372448   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "43147 -0.812192 -1.418069 -0.032134  0.531899  0.459979  0.691003  0.667206   \n",
       "43148  0.981355  1.525294  0.575249 -0.693447 -0.520257 -1.103283 -0.627225   \n",
       "43149 -0.812192  0.347949  2.397399 -0.989219 -1.010376  0.242432 -1.109289   \n",
       "43150  0.084582 -2.006742 -0.639517  0.214999  0.740047  0.691003  0.354757   \n",
       "43151  0.084582  0.347949 -0.639517  0.722038 -0.940359  0.242432  0.970728   \n",
       "\n",
       "              y         z  \n",
       "0      2.138209  1.738207  \n",
       "1      0.656710  0.537733  \n",
       "2      0.700284  0.791951  \n",
       "3      1.249310  1.243894  \n",
       "4      1.380030  1.399249  \n",
       "...         ...       ...  \n",
       "43147  0.674140  0.721335  \n",
       "43148 -0.633065 -0.676864  \n",
       "43149 -1.112374 -1.185299  \n",
       "43150  0.255834  0.396501  \n",
       "43151  0.918151  0.806074  \n",
       "\n",
       "[43152 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_features_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d417bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_process_ss = StandardScaler()\n",
    "train_labels_ss = label_process_ss.fit_transform(train_labels)\n",
    "test_labels_ss = label_process_ss.transform(test_labels)\n",
    "   \n",
    "#Make them dataframe\n",
    "df_train_labels_ss = pd.DataFrame(train_labels_ss, columns = [\"price\"])\n",
    "df_test_labels_ss  = pd.DataFrame(test_labels_ss, columns = [\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e7a00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e76c4567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ea4d7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nMLPRegressor(hidden_layer_sizes=(100,), activation='relu',  \\n             solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', \\n             learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \\n             random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \\n             nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, \\n             beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "MLPRegressor(hidden_layer_sizes=(100,), activation='relu',  \n",
    "             solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "             learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, \n",
    "             random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, \n",
    "             nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, \n",
    "             beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1798e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_pipeline = Pipeline([\n",
    "    ('model',MLPRegressor())\n",
    "    ])\n",
    "    \n",
    "\n",
    "params = [\n",
    "     {\n",
    "          \"model\":[MLPRegressor()],\n",
    "          \"model__alpha\":[1e-6,1e-3,1e1],\n",
    "          \"model__hidden_layer_sizes\":[(10,),(10,10,),(100,),(100,100,),(200,),(200,200,)],\n",
    "          #\"model__learning_rate\":['adaptive'],\n",
    "          \"model__activation\":['identity','relu']\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8bcd940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('model', MLPRegressor())]), n_jobs=-1,\n",
       "             param_grid=[{'model': [MLPRegressor(alpha=1e-06,\n",
       "                                                 hidden_layer_sizes=(100,\n",
       "                                                                     100))],\n",
       "                          'model__activation': ['identity', 'relu'],\n",
       "                          'model__alpha': [1e-06, 0.001, 10.0],\n",
       "                          'model__hidden_layer_sizes': [(10,), (10, 10), (100,),\n",
       "                                                        (100, 100), (200,),\n",
       "                                                        (200, 200)]}],\n",
       "             scoring='neg_root_mean_squared_error', verbose=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KFold(n_splits=5, shuffle=False, random_state=42)\n",
    "array_train = np.array(df_train_features_ss)\n",
    "array_label = np.array(df_train_labels_ss).ravel()\n",
    "\n",
    "g_s = GridSearchCV(default_pipeline, params,cv=KFold(n_splits=10,shuffle = True, random_state = 42),n_jobs=-1, scoring=('neg_root_mean_squared_error'),verbose=10,\n",
    "                    return_train_score=False)\n",
    "g_s.fit(array_train,array_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6b544d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn_grid_search.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(g_s, 'nn_grid_search.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2999afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "grid_search = joblib.load('nn_grid_search.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9317d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = pd.DataFrame(grid_search.cv_results_)\n",
    "sorted_g = df_g.sort_values(by='rank_test_score', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dd0fa51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__activation</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_model__hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>45.222993</td>\n",
       "      <td>7.887820</td>\n",
       "      <td>0.027459</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.146602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146476</td>\n",
       "      <td>-0.138329</td>\n",
       "      <td>-0.138206</td>\n",
       "      <td>-0.136564</td>\n",
       "      <td>-0.135141</td>\n",
       "      <td>-0.144128</td>\n",
       "      <td>-0.134930</td>\n",
       "      <td>-0.140744</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>162.155495</td>\n",
       "      <td>45.333820</td>\n",
       "      <td>0.091395</td>\n",
       "      <td>0.009584</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(200, 200)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.141133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183052</td>\n",
       "      <td>-0.138066</td>\n",
       "      <td>-0.137010</td>\n",
       "      <td>-0.132169</td>\n",
       "      <td>-0.137653</td>\n",
       "      <td>-0.142436</td>\n",
       "      <td>-0.135798</td>\n",
       "      <td>-0.141739</td>\n",
       "      <td>0.014074</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>153.309147</td>\n",
       "      <td>36.374703</td>\n",
       "      <td>0.093159</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(200, 200)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.146163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169017</td>\n",
       "      <td>-0.138796</td>\n",
       "      <td>-0.139307</td>\n",
       "      <td>-0.133798</td>\n",
       "      <td>-0.137246</td>\n",
       "      <td>-0.140154</td>\n",
       "      <td>-0.133103</td>\n",
       "      <td>-0.141795</td>\n",
       "      <td>0.009857</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>51.727427</td>\n",
       "      <td>16.256343</td>\n",
       "      <td>0.034580</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.149685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170605</td>\n",
       "      <td>-0.138158</td>\n",
       "      <td>-0.140546</td>\n",
       "      <td>-0.150330</td>\n",
       "      <td>-0.131856</td>\n",
       "      <td>-0.159765</td>\n",
       "      <td>-0.133393</td>\n",
       "      <td>-0.145606</td>\n",
       "      <td>0.011817</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30.418325</td>\n",
       "      <td>7.079172</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.151104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.213336</td>\n",
       "      <td>-0.145471</td>\n",
       "      <td>-0.140429</td>\n",
       "      <td>-0.138937</td>\n",
       "      <td>-0.144531</td>\n",
       "      <td>-0.177243</td>\n",
       "      <td>-0.141068</td>\n",
       "      <td>-0.153352</td>\n",
       "      <td>0.022717</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15.638937</td>\n",
       "      <td>3.008733</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.151190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278928</td>\n",
       "      <td>-0.147009</td>\n",
       "      <td>-0.153997</td>\n",
       "      <td>-0.142780</td>\n",
       "      <td>-0.134544</td>\n",
       "      <td>-0.151119</td>\n",
       "      <td>-0.141400</td>\n",
       "      <td>-0.158619</td>\n",
       "      <td>0.040554</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>16.998183</td>\n",
       "      <td>3.134386</td>\n",
       "      <td>0.009520</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.151082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.304496</td>\n",
       "      <td>-0.140992</td>\n",
       "      <td>-0.144878</td>\n",
       "      <td>-0.141101</td>\n",
       "      <td>-0.142535</td>\n",
       "      <td>-0.164883</td>\n",
       "      <td>-0.133844</td>\n",
       "      <td>-0.160712</td>\n",
       "      <td>0.048596</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27.723284</td>\n",
       "      <td>5.212073</td>\n",
       "      <td>0.018010</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.147129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379456</td>\n",
       "      <td>-0.142312</td>\n",
       "      <td>-0.140776</td>\n",
       "      <td>-0.140350</td>\n",
       "      <td>-0.137916</td>\n",
       "      <td>-0.149500</td>\n",
       "      <td>-0.142656</td>\n",
       "      <td>-0.166074</td>\n",
       "      <td>0.071215</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8.665704</td>\n",
       "      <td>1.432356</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.160103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337950</td>\n",
       "      <td>-0.148214</td>\n",
       "      <td>-0.148535</td>\n",
       "      <td>-0.145208</td>\n",
       "      <td>-0.144697</td>\n",
       "      <td>-0.154988</td>\n",
       "      <td>-0.147127</td>\n",
       "      <td>-0.167911</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.453995</td>\n",
       "      <td>2.344614</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.153379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366214</td>\n",
       "      <td>-0.149524</td>\n",
       "      <td>-0.158647</td>\n",
       "      <td>-0.144864</td>\n",
       "      <td>-0.156982</td>\n",
       "      <td>-0.168550</td>\n",
       "      <td>-0.154304</td>\n",
       "      <td>-0.174527</td>\n",
       "      <td>0.064265</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "21      45.222993      7.887820         0.027459        0.001679   \n",
       "23     162.155495     45.333820         0.091395        0.009584   \n",
       "29     153.309147     36.374703         0.093159        0.019402   \n",
       "27      51.727427     16.256343         0.034580        0.005234   \n",
       "28      30.418325      7.079172         0.022829        0.004340   \n",
       "26      15.638937      3.008733         0.009222        0.001271   \n",
       "20      16.998183      3.134386         0.009520        0.001041   \n",
       "22      27.723284      5.212073         0.018010        0.002067   \n",
       "25       8.665704      1.432356         0.002275        0.000358   \n",
       "19       9.453995      2.344614         0.002275        0.000481   \n",
       "\n",
       "                                          param_model param_model__activation  \\\n",
       "21  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                    relu   \n",
       "23  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                    relu   \n",
       "29  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                    relu   \n",
       "27  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                    relu   \n",
       "28  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                    relu   \n",
       "26  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                    relu   \n",
       "20  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                    relu   \n",
       "22  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                    relu   \n",
       "25  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                    relu   \n",
       "19  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                    relu   \n",
       "\n",
       "   param_model__alpha param_model__hidden_layer_sizes  \\\n",
       "21           0.000001                      (100, 100)   \n",
       "23           0.000001                      (200, 200)   \n",
       "29              0.001                      (200, 200)   \n",
       "27              0.001                      (100, 100)   \n",
       "28              0.001                          (200,)   \n",
       "26              0.001                          (100,)   \n",
       "20           0.000001                          (100,)   \n",
       "22           0.000001                          (200,)   \n",
       "25              0.001                        (10, 10)   \n",
       "19           0.000001                        (10, 10)   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "21  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.146602  ...   \n",
       "23  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.141133  ...   \n",
       "29  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.146163  ...   \n",
       "27  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.149685  ...   \n",
       "28  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.151104  ...   \n",
       "26  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.151190  ...   \n",
       "20  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.151082  ...   \n",
       "22  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.147129  ...   \n",
       "25  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.160103  ...   \n",
       "19  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.153379  ...   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "21          -0.146476          -0.138329          -0.138206   \n",
       "23          -0.183052          -0.138066          -0.137010   \n",
       "29          -0.169017          -0.138796          -0.139307   \n",
       "27          -0.170605          -0.138158          -0.140546   \n",
       "28          -0.213336          -0.145471          -0.140429   \n",
       "26          -0.278928          -0.147009          -0.153997   \n",
       "20          -0.304496          -0.140992          -0.144878   \n",
       "22          -0.379456          -0.142312          -0.140776   \n",
       "25          -0.337950          -0.148214          -0.148535   \n",
       "19          -0.366214          -0.149524          -0.158647   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "21          -0.136564          -0.135141          -0.144128   \n",
       "23          -0.132169          -0.137653          -0.142436   \n",
       "29          -0.133798          -0.137246          -0.140154   \n",
       "27          -0.150330          -0.131856          -0.159765   \n",
       "28          -0.138937          -0.144531          -0.177243   \n",
       "26          -0.142780          -0.134544          -0.151119   \n",
       "20          -0.141101          -0.142535          -0.164883   \n",
       "22          -0.140350          -0.137916          -0.149500   \n",
       "25          -0.145208          -0.144697          -0.154988   \n",
       "19          -0.144864          -0.156982          -0.168550   \n",
       "\n",
       "    split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "21          -0.134930        -0.140744        0.004454                1  \n",
       "23          -0.135798        -0.141739        0.014074                2  \n",
       "29          -0.133103        -0.141795        0.009857                3  \n",
       "27          -0.133393        -0.145606        0.011817                4  \n",
       "28          -0.141068        -0.153352        0.022717                5  \n",
       "26          -0.141400        -0.158619        0.040554                6  \n",
       "20          -0.133844        -0.160712        0.048596                7  \n",
       "22          -0.142656        -0.166074        0.071215                8  \n",
       "25          -0.147127        -0.167911        0.056872                9  \n",
       "19          -0.154304        -0.174527        0.064265               10  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_g[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a333f003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2:  0.9798190706850282\n",
      "Test RMSE:  0.141957205127966\n"
     ]
    }
   ],
   "source": [
    "preds = g_s.predict(np.array(df_test_features_ss))\n",
    "r2 = r2_score(np.array(df_test_labels_ss).ravel(), preds)\n",
    "rmse = mean_squared_error(np.array(df_test_labels_ss).ravel(), preds, squared=False)\n",
    "print(\"Test R2: \" ,r2)\n",
    "print(\"Test RMSE: \" ,rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "080a32b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__activation</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_model__hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.052393</td>\n",
       "      <td>0.665195</td>\n",
       "      <td>0.001049</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.294358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287695</td>\n",
       "      <td>-0.306710</td>\n",
       "      <td>-0.344191</td>\n",
       "      <td>-0.308652</td>\n",
       "      <td>-0.298077</td>\n",
       "      <td>-0.307024</td>\n",
       "      <td>-0.307009</td>\n",
       "      <td>-0.305863</td>\n",
       "      <td>0.014263</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.064571</td>\n",
       "      <td>0.347738</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.296134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288577</td>\n",
       "      <td>-0.308891</td>\n",
       "      <td>-0.342123</td>\n",
       "      <td>-0.306001</td>\n",
       "      <td>-0.298139</td>\n",
       "      <td>-0.305886</td>\n",
       "      <td>-0.307701</td>\n",
       "      <td>-0.306245</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.785478</td>\n",
       "      <td>0.439056</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.294926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290164</td>\n",
       "      <td>-0.308318</td>\n",
       "      <td>-0.340267</td>\n",
       "      <td>-0.307712</td>\n",
       "      <td>-0.296673</td>\n",
       "      <td>-0.307949</td>\n",
       "      <td>-0.308688</td>\n",
       "      <td>-0.306278</td>\n",
       "      <td>0.012906</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.106434</td>\n",
       "      <td>0.545078</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.294766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288767</td>\n",
       "      <td>-0.309846</td>\n",
       "      <td>-0.341276</td>\n",
       "      <td>-0.307328</td>\n",
       "      <td>-0.298267</td>\n",
       "      <td>-0.306122</td>\n",
       "      <td>-0.307338</td>\n",
       "      <td>-0.306279</td>\n",
       "      <td>0.013279</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.562126</td>\n",
       "      <td>6.536057</td>\n",
       "      <td>0.023864</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.295773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.297264</td>\n",
       "      <td>-0.310687</td>\n",
       "      <td>-0.338595</td>\n",
       "      <td>-0.307001</td>\n",
       "      <td>-0.297685</td>\n",
       "      <td>-0.305967</td>\n",
       "      <td>-0.309969</td>\n",
       "      <td>-0.307125</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.486355</td>\n",
       "      <td>0.864034</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.295490</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294193</td>\n",
       "      <td>-0.308346</td>\n",
       "      <td>-0.339792</td>\n",
       "      <td>-0.307934</td>\n",
       "      <td>-0.301484</td>\n",
       "      <td>-0.305996</td>\n",
       "      <td>-0.311729</td>\n",
       "      <td>-0.307265</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.805835</td>\n",
       "      <td>2.858200</td>\n",
       "      <td>0.010573</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.298185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289384</td>\n",
       "      <td>-0.307657</td>\n",
       "      <td>-0.347127</td>\n",
       "      <td>-0.307920</td>\n",
       "      <td>-0.301653</td>\n",
       "      <td>-0.306471</td>\n",
       "      <td>-0.308199</td>\n",
       "      <td>-0.307661</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.995470</td>\n",
       "      <td>0.244919</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.295962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.288251</td>\n",
       "      <td>-0.310154</td>\n",
       "      <td>-0.354826</td>\n",
       "      <td>-0.307723</td>\n",
       "      <td>-0.299113</td>\n",
       "      <td>-0.308274</td>\n",
       "      <td>-0.309332</td>\n",
       "      <td>-0.308076</td>\n",
       "      <td>0.016936</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>56.095807</td>\n",
       "      <td>28.935212</td>\n",
       "      <td>0.077110</td>\n",
       "      <td>0.007956</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(200, 200)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.305495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290545</td>\n",
       "      <td>-0.308180</td>\n",
       "      <td>-0.341484</td>\n",
       "      <td>-0.305981</td>\n",
       "      <td>-0.300365</td>\n",
       "      <td>-0.308790</td>\n",
       "      <td>-0.308807</td>\n",
       "      <td>-0.308760</td>\n",
       "      <td>0.012229</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.290193</td>\n",
       "      <td>0.734663</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.294398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290254</td>\n",
       "      <td>-0.311339</td>\n",
       "      <td>-0.352489</td>\n",
       "      <td>-0.305651</td>\n",
       "      <td>-0.304864</td>\n",
       "      <td>-0.305884</td>\n",
       "      <td>-0.312739</td>\n",
       "      <td>-0.309167</td>\n",
       "      <td>0.016079</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.486781</td>\n",
       "      <td>9.373967</td>\n",
       "      <td>0.022762</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.312452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290905</td>\n",
       "      <td>-0.312015</td>\n",
       "      <td>-0.340505</td>\n",
       "      <td>-0.313232</td>\n",
       "      <td>-0.298379</td>\n",
       "      <td>-0.309067</td>\n",
       "      <td>-0.311722</td>\n",
       "      <td>-0.309362</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.861358</td>\n",
       "      <td>16.416370</td>\n",
       "      <td>0.074332</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>(200, 200)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.301422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.316344</td>\n",
       "      <td>-0.307774</td>\n",
       "      <td>-0.340260</td>\n",
       "      <td>-0.307684</td>\n",
       "      <td>-0.296982</td>\n",
       "      <td>-0.308078</td>\n",
       "      <td>-0.310024</td>\n",
       "      <td>-0.309991</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.828945</td>\n",
       "      <td>0.464092</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.325280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.344079</td>\n",
       "      <td>-0.342378</td>\n",
       "      <td>-0.348706</td>\n",
       "      <td>-0.339915</td>\n",
       "      <td>-0.341006</td>\n",
       "      <td>-0.369340</td>\n",
       "      <td>-0.339218</td>\n",
       "      <td>-0.342561</td>\n",
       "      <td>0.010589</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.847516</td>\n",
       "      <td>0.897640</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.323709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345603</td>\n",
       "      <td>-0.342643</td>\n",
       "      <td>-0.346356</td>\n",
       "      <td>-0.340533</td>\n",
       "      <td>-0.339170</td>\n",
       "      <td>-0.367750</td>\n",
       "      <td>-0.341191</td>\n",
       "      <td>-0.342682</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.017142</td>\n",
       "      <td>0.603934</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(200,)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.325701</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340624</td>\n",
       "      <td>-0.350164</td>\n",
       "      <td>-0.346756</td>\n",
       "      <td>-0.345055</td>\n",
       "      <td>-0.339560</td>\n",
       "      <td>-0.369085</td>\n",
       "      <td>-0.340681</td>\n",
       "      <td>-0.343221</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.308299</td>\n",
       "      <td>0.604920</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.327091</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.350382</td>\n",
       "      <td>-0.344779</td>\n",
       "      <td>-0.351741</td>\n",
       "      <td>-0.347363</td>\n",
       "      <td>-0.343847</td>\n",
       "      <td>-0.377457</td>\n",
       "      <td>-0.344003</td>\n",
       "      <td>-0.347245</td>\n",
       "      <td>0.011897</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.234400</td>\n",
       "      <td>2.398480</td>\n",
       "      <td>0.026919</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(100, 100)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.331911</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.356155</td>\n",
       "      <td>-0.350622</td>\n",
       "      <td>-0.352183</td>\n",
       "      <td>-0.359103</td>\n",
       "      <td>-0.341144</td>\n",
       "      <td>-0.380833</td>\n",
       "      <td>-0.346954</td>\n",
       "      <td>-0.351157</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>53.582684</td>\n",
       "      <td>20.526465</td>\n",
       "      <td>0.069583</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...</td>\n",
       "      <td>identity</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(200, 200)</td>\n",
       "      <td>{'model': MLPRegressor(alpha=1e-06, hidden_lay...</td>\n",
       "      <td>-0.325970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359567</td>\n",
       "      <td>-0.354244</td>\n",
       "      <td>-0.352817</td>\n",
       "      <td>-0.342723</td>\n",
       "      <td>-0.341165</td>\n",
       "      <td>-0.376790</td>\n",
       "      <td>-0.356747</td>\n",
       "      <td>-0.353035</td>\n",
       "      <td>0.013391</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6        2.052393      0.665195         0.001049        0.000159   \n",
       "1        2.064571      0.347738         0.001776        0.000455   \n",
       "0        1.785478      0.439056         0.000901        0.000300   \n",
       "7        2.106434      0.545078         0.001681        0.000387   \n",
       "3       17.562126      6.536057         0.023864        0.004595   \n",
       "8        2.486355      0.864034         0.005306        0.000847   \n",
       "10       5.805835      2.858200         0.010573        0.002023   \n",
       "2        1.995470      0.244919         0.006043        0.002383   \n",
       "11      56.095807     28.935212         0.077110        0.007956   \n",
       "4        3.290193      0.734663         0.009761        0.001665   \n",
       "9       22.486781      9.373967         0.022762        0.002117   \n",
       "5       50.861358     16.416370         0.074332        0.006812   \n",
       "14       2.828945      0.464092         0.005702        0.001664   \n",
       "12       2.847516      0.897640         0.001254        0.000404   \n",
       "16       4.017142      0.603934         0.010155        0.001440   \n",
       "13       3.308299      0.604920         0.001599        0.000490   \n",
       "15      13.234400      2.398480         0.026919        0.006319   \n",
       "17      53.582684     20.526465         0.069583        0.004211   \n",
       "\n",
       "                                          param_model param_model__activation  \\\n",
       "6   MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "1   MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "0   MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "7   MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "3   MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "8   MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "10  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "2   MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "11  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "4   MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "9   MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "5   MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "14  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "12  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "16  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "13  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "15  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "17  MLPRegressor(alpha=1e-06, hidden_layer_sizes=(...                identity   \n",
       "\n",
       "   param_model__alpha param_model__hidden_layer_sizes  \\\n",
       "6               0.001                           (10,)   \n",
       "1            0.000001                        (10, 10)   \n",
       "0            0.000001                           (10,)   \n",
       "7               0.001                        (10, 10)   \n",
       "3            0.000001                      (100, 100)   \n",
       "8               0.001                          (100,)   \n",
       "10              0.001                          (200,)   \n",
       "2            0.000001                          (100,)   \n",
       "11              0.001                      (200, 200)   \n",
       "4            0.000001                          (200,)   \n",
       "9               0.001                      (100, 100)   \n",
       "5            0.000001                      (200, 200)   \n",
       "14               10.0                          (100,)   \n",
       "12               10.0                           (10,)   \n",
       "16               10.0                          (200,)   \n",
       "13               10.0                        (10, 10)   \n",
       "15               10.0                      (100, 100)   \n",
       "17               10.0                      (200, 200)   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "6   {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.294358  ...   \n",
       "1   {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.296134  ...   \n",
       "0   {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.294926  ...   \n",
       "7   {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.294766  ...   \n",
       "3   {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.295773  ...   \n",
       "8   {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.295490  ...   \n",
       "10  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.298185  ...   \n",
       "2   {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.295962  ...   \n",
       "11  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.305495  ...   \n",
       "4   {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.294398  ...   \n",
       "9   {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.312452  ...   \n",
       "5   {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.301422  ...   \n",
       "14  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.325280  ...   \n",
       "12  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.323709  ...   \n",
       "16  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.325701  ...   \n",
       "13  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.327091  ...   \n",
       "15  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.331911  ...   \n",
       "17  {'model': MLPRegressor(alpha=1e-06, hidden_lay...          -0.325970  ...   \n",
       "\n",
       "    split3_test_score  split4_test_score  split5_test_score  \\\n",
       "6           -0.287695          -0.306710          -0.344191   \n",
       "1           -0.288577          -0.308891          -0.342123   \n",
       "0           -0.290164          -0.308318          -0.340267   \n",
       "7           -0.288767          -0.309846          -0.341276   \n",
       "3           -0.297264          -0.310687          -0.338595   \n",
       "8           -0.294193          -0.308346          -0.339792   \n",
       "10          -0.289384          -0.307657          -0.347127   \n",
       "2           -0.288251          -0.310154          -0.354826   \n",
       "11          -0.290545          -0.308180          -0.341484   \n",
       "4           -0.290254          -0.311339          -0.352489   \n",
       "9           -0.290905          -0.312015          -0.340505   \n",
       "5           -0.316344          -0.307774          -0.340260   \n",
       "14          -0.344079          -0.342378          -0.348706   \n",
       "12          -0.345603          -0.342643          -0.346356   \n",
       "16          -0.340624          -0.350164          -0.346756   \n",
       "13          -0.350382          -0.344779          -0.351741   \n",
       "15          -0.356155          -0.350622          -0.352183   \n",
       "17          -0.359567          -0.354244          -0.352817   \n",
       "\n",
       "    split6_test_score  split7_test_score  split8_test_score  \\\n",
       "6           -0.308652          -0.298077          -0.307024   \n",
       "1           -0.306001          -0.298139          -0.305886   \n",
       "0           -0.307712          -0.296673          -0.307949   \n",
       "7           -0.307328          -0.298267          -0.306122   \n",
       "3           -0.307001          -0.297685          -0.305967   \n",
       "8           -0.307934          -0.301484          -0.305996   \n",
       "10          -0.307920          -0.301653          -0.306471   \n",
       "2           -0.307723          -0.299113          -0.308274   \n",
       "11          -0.305981          -0.300365          -0.308790   \n",
       "4           -0.305651          -0.304864          -0.305884   \n",
       "9           -0.313232          -0.298379          -0.309067   \n",
       "5           -0.307684          -0.296982          -0.308078   \n",
       "14          -0.339915          -0.341006          -0.369340   \n",
       "12          -0.340533          -0.339170          -0.367750   \n",
       "16          -0.345055          -0.339560          -0.369085   \n",
       "13          -0.347363          -0.343847          -0.377457   \n",
       "15          -0.359103          -0.341144          -0.380833   \n",
       "17          -0.342723          -0.341165          -0.376790   \n",
       "\n",
       "    split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "6           -0.307009        -0.305863        0.014263               19  \n",
       "1           -0.307701        -0.306245        0.013496               20  \n",
       "0           -0.308688        -0.306278        0.012906               21  \n",
       "7           -0.307338        -0.306279        0.013279               22  \n",
       "3           -0.309969        -0.307125        0.011619               23  \n",
       "8           -0.311729        -0.307265        0.012133               24  \n",
       "10          -0.308199        -0.307661        0.014262               25  \n",
       "2           -0.309332        -0.308076        0.016936               26  \n",
       "11          -0.308807        -0.308760        0.012229               27  \n",
       "4           -0.312739        -0.309167        0.016079               28  \n",
       "9           -0.311722        -0.309362        0.012503               29  \n",
       "5           -0.310024        -0.309991        0.011199               30  \n",
       "14          -0.339218        -0.342561        0.010589               31  \n",
       "12          -0.341191        -0.342682        0.010253               32  \n",
       "16          -0.340681        -0.343221        0.010724               33  \n",
       "13          -0.344003        -0.347245        0.011897               34  \n",
       "15          -0.346954        -0.351157        0.012270               35  \n",
       "17          -0.356747        -0.353035        0.013391               36  \n",
       "\n",
       "[18 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RELU Show off\n",
    "#Identity performs similar to linear regression\n",
    "sorted_g.loc[sorted_g['param_model__activation'] == 'identity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfd147f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30821918314476354, 0.14004087951847932]\n",
      "[0.9048638415420397, 0.9803602506904753]\n"
     ]
    }
   ],
   "source": [
    "rms_list = []\n",
    "r2_list = []\n",
    "\n",
    "clf_id = MLPRegressor(alpha =0.001  ,hidden_layer_sizes=(10), activation = 'identity')\n",
    "\n",
    "model_fit = clf_id.fit(array_train,array_label)\n",
    "preds = model_fit.predict(np.array(df_test_features_ss))\n",
    "r2 = r2_score(np.array(df_test_labels_ss).ravel(), preds)\n",
    "rmse = mean_squared_error(np.array(df_test_labels_ss).ravel(), preds, squared=False)\n",
    "rms_list.append(rmse)\n",
    "r2_list.append(r2)\n",
    "\n",
    "clf_relu = MLPRegressor(alpha =0.000001 ,hidden_layer_sizes=(100, 100), activation = 'relu')\n",
    "model_fit = clf_relu.fit(array_train,array_label)\n",
    "preds = model_fit.predict(np.array(df_test_features_ss))\n",
    "r2 = r2_score(np.array(df_test_labels_ss).ravel(), preds)\n",
    "rmse = mean_squared_error(np.array(df_test_labels_ss).ravel(), preds, squared=False)\n",
    "rms_list.append(rmse)\n",
    "r2_list.append(r2)\n",
    "\n",
    "\n",
    "print(rms_list)\n",
    "print(r2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cff8060c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGxCAYAAACeKZf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCgklEQVR4nO3dd3hUdd7//9eQMqGXACFASKIIhCqCIiBCkLKA3sgqoID0VUBBwAZyK1W5VUTUFVEJYBSRRYriRopAABdWqbsgiFKDQAyJ9BJS3r8/+GW+DikkmhA4Ph/XNdeV+ZzPOZ/3nMyZec0pMy4zMwEAADhEkcIuAAAAID8RbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbgAAgKMQbvCHzZkzRy6XS5s3b75q3759+yosLKxA69m1a5fGjRungwcP5mr8l19+WUuWLCnQmvJbbGysXC6X5+bj46MKFSrovvvuy9X/ISsHDx6Uy+XSlClTsu0TFhame++9N8tpmzdvlsvl0pw5c3I95hdffCGXy6XAwEAlJyfntWRJ0vnz5zVu3DjFxsZmmpbx3MzquZBfYmJiNG7cuCynhYWFqW/fvgU2dk5WrVqlxo0bq3jx4nK5XAX6HM947mTcihQporJly+qee+7RihUrMvVftGiRHn74YVWvXl1FixZVWFiYevbsqZ9++ilX45mZPv30U7Vo0UIVK1ZUQECAqlatqvbt22vmzJn5/fBwAyLcwHF27dql8ePHZ/mG9sILL2jx4sVebTdiuMnw8ssva+PGjYqNjdULL7ygDRs2qGXLlrl+kyhsUVFRkqRff/31d/8Pzp8/r/Hjx2cZbjp16qSNGzcqODj4D1SZs5iYGI0fPz7LaYsXL9YLL7xQYGNnx8zUrVs3+fn56YsvvtDGjRvVsmXLAh936NCh2rhxo9avX68pU6bop59+UseOHbVu3Tqvfq+88orOnz+vMWPGaNmyZZo0aZK2bdum2267Td9///1Vxxk9erQefvhhRUREaObMmfrqq680adIkBQUF6fPPPy+oh4cbiG9hFwBcSzfffHNhl5CvbrnlFt15552SpBYtWqhMmTLq06ePPv7442zfcK8X8fHxiomJUevWrbVhwwZFRUWpe/fu+TpGhQoVVKFChXxdZl40bNiwUMY9evSofv31V3Xp0kX33HNPvizzwoULCggIkMvlyrZPtWrVPM/H5s2b65ZbblHLli0VFRWlu+++29Nv6dKlqlixote8rVu3VlhYmN54440c975cuHBB06ZNU+/evfX+++97Tevbt6/S09N/z8P73S5cuKCiRYte0zFxdey5QYGZM2eOatasKbfbrYiICEVHR2fZ79KlS5o0aZJq1aolt9utChUqqF+/fjp+/LhXv4xDIsuWLdNtt92mokWLqlatWpo1a5bXmF27dpUkRUZGenaTZxwqufKwlMvl0rlz5/Thhx96+rZq1UoHDx6Ur6+vJk+enKnedevWyeVyacGCBVk+nuPHj8vf3z/LT+w//PCDXC6X3nrrLUmX9zo8/fTTCg8PV0BAgMqVK6fGjRtr3rx52a/YHDRu3FiS9Msvv3i1//TTT+rRo4cqVqzo+X+88847v2uM/PLhhx8qNTVVI0aM0F//+letWrVKhw4dytTv5MmTeuqpp3TTTTfJ7XarYsWK6tixo3744QcdPHjQE17Gjx/v+R9mHAq68rDU8OHDVbx4cZ0+fTrTON27d1dQUJBSUlIkSfPnz1e7du0UHBysokWLKiIiQqNGjdK5c+c88/Tt29ezHn97WCZjvKwOS8XFxalXr15e/4vXX3/d6035t4cIp06dqvDwcJUoUUJNmzbVv//97xzX67hx41S1alVJ0nPPPSeXy+X1nP/mm290zz33qGTJkipWrJiaNWumf/7zn17LyFhvK1asUP/+/VWhQgUVK1Ysz4cOs3s+XhlsJKly5cqqWrWqDh8+nOMyz507p+Tk5Gz3xhUp4v22lpycrAkTJigiIkIBAQEKDAxUZGSkNmzY4Olz8eJFjR49WuHh4fL391eVKlX0+OOP6+TJk17LyngNWrRokRo2bKiAgADPh4j4+Hg99thjqlq1qvz9/RUeHq7x48crNTU1x8eDAmLAHzR79myTZJs2bcrU1rlzZ1u6dKl9/PHHVr16dQsJCbHQ0FBPv7S0NPvLX/5ixYsXt/Hjx9vKlStt5syZVqVKFatdu7adP3/e0zc0NNSqVq1qtWvXtujoaFu+fLl17drVJNnatWvNzCwhIcFefvllk2TvvPOObdy40TZu3GgJCQlmZtanTx+v8Tdu3GhFixa1jh07evp+//33ZmbWpUsXq1atmqWmpno93q5du1rlypUtJSUl23XSpUsXCwkJsbS0NK/2Z5991vz9/S0xMdHMzB577DErVqyYTZ061dasWWNffvml/d///Z+9/fbbOa7zNWvWmCRbsGCBV/uXX35pkuz111/3tH3//fdWunRpq1evnkVHR9uKFSvsqaeesiJFiti4ceM8/Q4cOGCS7LXXXst23NDQUOvUqVOW0zZt2mSSbPbs2TnWnqFGjRoWHBxsqamp9vXXX5skr3rMzE6fPm116tSx4sWL24QJE2z58uW2cOFCe/LJJ2316tV28eJFW7ZsmUmyAQMGeP6He/fuNbP/9zw8cOCAmZn95z//MUn2wQcfeI1z4sQJc7vdNnLkSE/bxIkT7Y033rB//vOfFhsbazNmzLDw8HCLjIz09Nm7d689+OCDJskz9saNG+3ixYue9dWnTx9P/4SEBKtSpYpVqFDBZsyYYcuWLbMnnnjCJNngwYM9/TL+F2FhYfaXv/zFlixZYkuWLLF69epZ2bJl7eTJk9mu18OHD9uiRYtMkg0dOtQ2btxoW7duNTOz2NhY8/Pzs0aNGtn8+fNtyZIl1q5dO3O5XPbpp596lpGx3qpUqWKPPvqoffXVV/bZZ59l2haurPfK587OnTs9dVzNvn37rEiRIjZixIir9q1evbqVLFnSXn/9ddu9e7elp6dn2S8lJcUiIyPN19fXnn76aYuJibEvvvjCnn/+eZs3b56ZmaWnp1v79u3N19fXXnjhBVuxYoVNmTLFihcvbg0bNvT8L80u/z+Dg4PtpptuslmzZtmaNWvsu+++s2PHjnle29577z37+uuvbeLEieZ2u61v375XfTzIf4Qb/GFXhpu0tDSrXLmy3XbbbV4vOgcPHjQ/Pz+vcDFv3jyTZAsXLvRaZsYb5fTp0z1toaGhFhAQYIcOHfK0XbhwwcqVK2ePPfaYp23BggUmydasWZOp1ivDjZlZ8eLFvd6AMmQEiMWLF3vajhw5Yr6+vjZ+/PicVol98cUXJslWrFjhaUtNTbXKlSvbAw884GmrW7eu3X///TkuKysZtc2fP99SUlLs/Pnz9q9//ctq1qxptWvXthMnTnj6tm/f3qpWrWqnTp3yWsYTTzxhAQEB9uuvv5rZtQ0369atM0k2atQoM7v8BhMeHm6hoaFez5kJEyaYJFu5cmW2yzp+/LhJsrFjx2aadmW4MTO77bbbrFmzZl79pk+fbpJsx44dWY6Rnp5uKSkptnbtWpNk//nPfzzTHn/8ccvuc+KV4WbUqFEmyb799luvfoMHDzaXy2V79uwxs//3v6hXr55XoPjuu+9MkueNOTvZ/S/vvPNOq1ixop05c8bTlpqaanXr1rWqVat61n3Geuvdu3eO41w53iuvvGIpKSl28eJF2759uzVt2tSCg4O91n9WUlJSrFWrVlaqVCmLi4u76njfffedVatWzSSZJCtZsqTde++9Fh0d7fX8iY6OzjLM/lZGOH711Ve92ufPn2+S7P333/e0hYaGmo+Pj+f/lOGxxx6zEiVKeL02mZlNmTLFJHk+MOHa4bAU8t2ePXt09OhR9ejRw+v4fGhoqJo1a+bV98svv1SZMmV03333KTU11XO79dZbValSpUwnid56662qVq2a535AQIBq1KiR5eGMP6pVq1Zq0KCB1+GbGTNmyOVy6dFHH81x3g4dOqhSpUqaPXu2p2358uU6evSo+vfv72m744479NVXX2nUqFGKjY3VhQsX8lRj9+7d5efnp2LFiql58+Y6ffq0/vnPf6pMmTKSLu9uX7Vqlbp06aJixYp5reOOHTvq4sWLVz3MURAyTiTOWBcZh5IOHTqkVatWefp99dVXqlGjhtq0aZNvY/fr108bNmzQnj17PG2zZ8/W7bffrrp163ra9u/frx49eqhSpUry8fGRn5+f56Tc3bt3/66xV69erdq1a+uOO+7wau/bt6/MTKtXr/Zq79Spk3x8fDz369evL0m/6/l+7tw5ffvtt3rwwQdVokQJT7uPj48eeeQR/fzzz17rRJIeeOCBPI3x3HPPyc/PTwEBAbr11lu1c+dOLV26NMcrJM1MAwYM0Pr16xUdHa2QkJCrjnP77bdr7969WrZsmZ5//nk1bdpUq1atUu/evfU///M/MjNJl58/AQEBXtvclTLW+ZWHD7t27arixYt7PR+ly/+DGjVqeLV9+eWXioyMVOXKlb22sQ4dOkiS1q5de9XHhPxFuEG+S0pKkiRVqlQp07Qr23755RedPHlS/v7+8vPz87rFx8crMTHRq39gYGCmZbrd7jyHgtwaNmyYVq1apT179iglJUUffPCBHnzwwSwf22/5+vrqkUce0eLFiz3H7efMmaPg4GC1b9/e0++tt97Sc889pyVLligyMlLlypXT/fffn+urnV555RVt2rRJa9eu1ZgxY/TLL7/o/vvv95wbkZSUpNTUVL399tuZ1m/Hjh0lKdM6vtrjSktLy3JaxrkFfn5+OS7jzJkzWrBgge644w5VqFBBJ0+e1MmTJ9WlSxe5XC5P8JEun7+Ucf5IfunZs6fcbrfnPKxdu3Zp06ZN6tevn6fP2bNn1aJFC3377beaNGmSYmNjtWnTJi1atEiSfvfzLSkpKctzRSpXruyZ/ltXPt/dbvfvHv/EiRMyszyNn9erzJ588klt2rRJ33zzjaZMmaKUlBR17tw503IzmJkGDhyojz/+WHPmzFHnzp1zPZafn5/at2+vl156ScuXL9fhw4fVqlUrffnll/rqq68kXX7+VK5cOdN5OL+VlJQkX1/fTCeeu1wuVapUKVfr5JdfftHSpUszbWN16tSRlLdtDPmDq6WQ7zJekOPj4zNNu7KtfPnyCgwM1LJly7JcVsmSJfO/wDzo0aOHnnvuOb3zzju68847FR8fr8cffzxX8/br10+vvfaaPv30U3Xv3l1ffPGFhg8f7vVJvHjx4ho/frzGjx+vX375xbMX57777tMPP/xw1TFuuukmz0mbd999t4oWLar//d//1dtvv62nn35aZcuW9Xwyz67u8PDwXD0eSQoKCtKRI0eynJbRHhQUlOMy5s2bp/Pnz+u7775T2bJlM01fvHixTpw4obJly6pChQr6+eefc11fbpQtW1adO3dWdHS0Jk2apNmzZysgIEAPP/ywp8/q1at19OhRxcbGel1CfeUJpnkVGBioY8eOZWo/evSopMvbQ0EpW7asihQpkqfxc7oyKitVq1b1PB+bN2+uSpUqqVevXho7dqz+/ve/e/XNCDazZ89WVFSUevXqlaexrhQYGKjhw4crNjZWO3fuVMeOHVWhQgV98803Sk9PzzbgBAYGKjU1VcePH/cKOGam+Ph43X777V79s1on5cuXV/369fXSSy9lOUZGeMS1w54b5LuaNWsqODhY8+bN8+weli7vSv/tFQqSdO+99yopKUlpaWlq3LhxplvNmjXzPH5eP93mtOcnICBAjz76qD788ENNnTpVt956q5o3b56r5UZERKhJkyaaPXu2PvnkEyUnJ3vtHbhSUFCQ+vbtq4cfflh79uzR+fPnczXObz377LOqXr26/u///k9nzpxRsWLFFBkZqW3btql+/fpZruOs9oZlp02bNtq5c6d27dqVado//vEPlShRQk2aNMlxGVFRUSpZsqRWrVqlNWvWeN1ee+01JScna+7cuZIuH9778ccfMx2u+a3fszejX79+Onr0qGJiYvTxxx+rS5cunkN50v97A8tYdob33nvvD41/zz33aNeuXdq6datXe3R0tFwulyIjI3P9GPKqePHiatKkiRYtWuRVa3p6uj7++GNVrVo10+GWP6pnz55q1aqVPvjgA69DaWamv/3tb5o9e7bee++9HLeLK6WkpGS7JyjjcGFGmOjQoYMuXryY4xdLZlwq//HHH3u1L1y4UOfOncvVpfT33nuvdu7cqZtvvjnLbYxwc+2x5wb5rkiRIpo4caIGDhyoLl266G9/+5tOnjypcePGZTqc89BDD2nu3Lnq2LGjnnzySd1xxx3y8/PTzz//rDVr1qhz587q0qVLnsbPOG/i/fffV8mSJRUQEKDw8PBs38Tr1aun2NhYLV26VMHBwSpZsqRXqBoyZIheffVVbdmyJc/fftq/f3899thjOnr0qJo1a5YprDVp0kT33nuv6tevr7Jly2r37t366KOP1LRpUxUrVixPY0mXd9W//PLL6tatm95880397//+r958803dddddatGihQYPHqywsDCdOXNGe/fu1dKlSzMFhx07duizzz7LtOzbb79dTz75pKKjo9WqVSs9//zzqlevnk6cOKH58+frs88+09SpU3Pc27Zz50599913Gjx4sFq3bp1pevPmzfX6668rKipKTzzxhIYPH6758+erc+fOGjVqlO644w5duHBBa9eu1b333qvIyEiVLFlSoaGh+vzzz3XPPfeoXLlyKl++fI7nebRr105Vq1bVkCFDFB8fn+nNtVmzZipbtqwGDRqksWPHys/PT3PnztV//vOfTMuqV6+epMuHCDt06CAfHx/Vr19f/v7+mfqOGDFC0dHR6tSpkyZMmKDQ0FD985//1PTp0zV48OB8DxdXmjx5stq2bavIyEg9/fTT8vf31/Tp07Vz507Nmzcvz3tqcuOVV15RkyZNNHHiRM/2M2zYMEVFRal///6qV6+e13lfbrc7x+8HOnXqlMLCwtS1a1e1adNGISEhOnv2rGJjY/Xmm28qIiJCf/3rXyVJDz/8sGbPnq1BgwZpz549ioyMVHp6ur799ltFRETooYceUtu2bdW+fXs999xzOn36tJo3b67//ve/Gjt2rBo2bKhHHnnkqo9xwoQJWrlypZo1a6Zhw4apZs2aunjxog4ePKiYmBjNmDEj3w+v4ioK7VRmOEZWl4Kbmc2cOdNuueUW8/f3txo1atisWbOyvFopJSXFpkyZYg0aNLCAgAArUaKE1apVyx577DH76aefPP2yu1KnZcuW1rJlS6+2adOmWXh4uPn4+HhdwZPV+Nu3b7fmzZtbsWLFTFKmZZmZtWrVysqVK+d1aXpunDp1yooWLZrtFRujRo2yxo0bW9myZc3tdttNN91kI0aM8Fwqnp3sLgXP0KRJE69Lhg8cOGD9+/e3KlWqmJ+fn1WoUMGaNWtmkyZN8syTccVLdreMdRgfH2+DBw+2atWqma+vr5UsWdLuuuuubGv5reHDh5sk2759e7Z9Mq4o2rJli5ldvkz7ySeftGrVqpmfn59VrFjROnXqZD/88INnnq+//toaNmxobrfbJHmuUMrqaqkMzz//vEnK8pJ9M7MNGzZY06ZNrVixYlahQgUbOHCgbd26NdMVYcnJyTZw4ECrUKGCuVwur/GuvFrKzOzQoUPWo0cPCwwMND8/P6tZs6a99tprXjXkdOWasrky7Ldymn/9+vXWunVrK168uBUtWtTuvPNOW7p0qVef7Lbp3zOe2eWvT/D19fVcoh8aGprt8+zK7fNKycnJNmXKFOvQoYNVq1bN3G63BQQEWEREhD377LOWlJTk1f/ChQv24osvel6LAgMDrXXr1rZhwwavPs8995yFhoaan5+fBQcH2+DBg72uOsyoO7urBY8fP27Dhg2z8PBw8/Pzs3LlylmjRo1szJgxdvbs2ausQeQ3l9lvjhsAyCQhIUGhoaEaOnSoXn311cIuBwBwFRyWArLx888/a//+/XrttddUpEgRPfnkk4VdEgAgFzihGMjGzJkz1apVK33//feaO3euqlSpUtglAQBygcNSAADAUdhzAwAAHIVwAwAAHIVwAwAAHOVPd7VUenq6jh49qpIlSxbIF1YBAID8Z2Y6c+bMVX8vTPoThpujR4/m6ldnAQDA9efw4cNX/cbnP124yfhq+MOHD6tUqVKFXA0AAMiN06dPKyQkJFc/qPynCzcZh6JKlSpFuAEA4AaTm1NKOKEYAAA4CuEGAAA4CuEGAAA4SqGGm3Xr1um+++5T5cqV5XK5tGTJkqvOs3btWjVq1EgBAQG66aabNGPGjIIvFAAA3DAKNdycO3dODRo00N///vdc9T9w4IA6duyoFi1aaNu2bXr++ec1bNgwLVy4sIArBQAAN4pCvVqqQ4cO6tChQ677z5gxQ9WqVdO0adMkSREREdq8ebOmTJmiBx54oICqBAAAN5Ib6pybjRs3ql27dl5t7du31+bNm5WSkpLlPMnJyTp9+rTXDQAAONcNFW7i4+MVFBTk1RYUFKTU1FQlJiZmOc/kyZNVunRpz41vJwYAwNluqHAjZf7yHjPLsj3D6NGjderUKc/t8OHDBV4jAAAoPDfUNxRXqlRJ8fHxXm0JCQny9fVVYGBglvO43W653e5rUR4AALgO3FB7bpo2baqVK1d6ta1YsUKNGzeWn59fIVUFAACuJ4Uabs6ePavt27dr+/btki5f6r19+3bFxcVJunxIqXfv3p7+gwYN0qFDhzRy5Ejt3r1bs2bNUlRUlJ5++unCKB8AAFyHCvWw1ObNmxUZGem5P3LkSElSnz59NGfOHB07dswTdCQpPDxcMTExGjFihN555x1VrlxZb731FpeBAwAAD5dlnJH7J3H69GmVLl1ap06d4lfBAfwucXFx2V6hCUAqX768qlWrlq/LzMv79w11QjEAFLa4uDjVrBWhixfOF3YpwHUroGgx7flhd74HnNwi3ABAHiQmJurihfMKvPcp+QXyvVnAlVKSDivpy9eVmJhIuAGAG4lfYIjclaoXdhkAsnBDXQoOAABwNYQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKL6FXYDTxMXFKTExsbDLAK5L5cuXV7Vq1Qq7DAAOR7jJR3FxcapZK0IXL5wv7FKA61JA0WLa88NuAg6AAkW4yUeJiYm6eOG8Au99Sn6BIYVdDnBdSUk6rKQvX1diYiLhBkCBItwUAL/AELkrVS/sMgAA+FPihGIAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohBsAAOAohR5upk+frvDwcAUEBKhRo0Zav359jv3nzp2rBg0aqFixYgoODla/fv2UlJR0jaoFAADXu0INN/Pnz9fw4cM1ZswYbdu2TS1atFCHDh0UFxeXZf9vvvlGvXv31oABA/T9999rwYIF2rRpkwYOHHiNKwcAANerQg03U6dO1YABAzRw4EBFRERo2rRpCgkJ0bvvvptl/3//+98KCwvTsGHDFB4errvuukuPPfaYNm/efI0rBwAA16tCCzeXLl3Sli1b1K5dO6/2du3aacOGDVnO06xZM/3888+KiYmRmemXX37RZ599pk6dOmU7TnJysk6fPu11AwAAzlVo4SYxMVFpaWkKCgryag8KClJ8fHyW8zRr1kxz585V9+7d5e/vr0qVKqlMmTJ6++23sx1n8uTJKl26tOcWEhKSr48DAABcXwr9hGKXy+V138wytWXYtWuXhg0bphdffFFbtmzRsmXLdODAAQ0aNCjb5Y8ePVqnTp3y3A4fPpyv9QMAgOuLb2ENXL58efn4+GTaS5OQkJBpb06GyZMnq3nz5nrmmWckSfXr11fx4sXVokULTZo0ScHBwZnmcbvdcrvd+f8AAADAdanQ9tz4+/urUaNGWrlypVf7ypUr1axZsyznOX/+vIoU8S7Zx8dH0uU9PgAAAIV6WGrkyJGaOXOmZs2apd27d2vEiBGKi4vzHGYaPXq0evfu7el/3333adGiRXr33Xe1f/9+/etf/9KwYcN0xx13qHLlyoX1MAAAwHWk0A5LSVL37t2VlJSkCRMm6NixY6pbt65iYmIUGhoqSTp27JjXd9707dtXZ86c0d///nc99dRTKlOmjFq3bq1XXnmlsB4CAAC4zhRquJGkIUOGaMiQIVlOmzNnTqa2oUOHaujQoQVcFQAAuFEV+tVSAAAA+YlwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHIVwAwAAHKXQw8306dMVHh6ugIAANWrUSOvXr8+xf3JyssaMGaPQ0FC53W7dfPPNmjVr1jWqFgAAXO98C3Pw+fPna/jw4Zo+fbqaN2+u9957Tx06dNCuXbtUrVq1LOfp1q2bfvnlF0VFRal69epKSEhQamrqNa4cAABcrwo13EydOlUDBgzQwIEDJUnTpk3T8uXL9e6772ry5MmZ+i9btkxr167V/v37Va5cOUlSWFjYtSwZAABc5wrtsNSlS5e0ZcsWtWvXzqu9Xbt22rBhQ5bzfPHFF2rcuLFeffVVValSRTVq1NDTTz+tCxcuZDtOcnKyTp8+7XUDAADOVWh7bhITE5WWlqagoCCv9qCgIMXHx2c5z/79+/XNN98oICBAixcvVmJiooYMGaJff/012/NuJk+erPHjx+d7/QAA4PpU6CcUu1wur/tmlqktQ3p6ulwul+bOnas77rhDHTt21NSpUzVnzpxs996MHj1ap06d8twOHz6c748BAABcPwptz0358uXl4+OTaS9NQkJCpr05GYKDg1WlShWVLl3a0xYRESEz088//6xbbrkl0zxut1tutzt/iwcAANetQttz4+/vr0aNGmnlypVe7StXrlSzZs2ynKd58+Y6evSozp4962n78ccfVaRIEVWtWrVA6wUAADeGQj0sNXLkSM2cOVOzZs3S7t27NWLECMXFxWnQoEGSLh9S6t27t6d/jx49FBgYqH79+mnXrl1at26dnnnmGfXv319FixYtrIcBAACuI4V6KXj37t2VlJSkCRMm6NixY6pbt65iYmIUGhoqSTp27Jji4uI8/UuUKKGVK1dq6NChaty4sQIDA9WtWzdNmjSpsB4CAAC4zhRquJGkIUOGaMiQIVlOmzNnTqa2WrVqZTqUBQAAkKHQr5YCAADIT3kKN9OnT1ebNm3UrVs3rV692mtaYmKibrrppnwtDgAAIK9yHW7eeustPfPMM6pVq5bcbrc6duzo9RMJaWlpOnToUIEUCQAAkFu5Pufmvffe0wcffKAePXpIunyuzP33368LFy5owoQJBVYgAABAXuQ63Bw4cMDr+2eaNm2q1atX65577lFKSoqGDx9eEPUBAADkSa7DTfny5XX48GGvX+GuU6eOVq9erdatW+vIkSMFUR8AAECe5Pqcm7vuuksLFy7M1F67dm2tWrVKy5Yty9fCAAAAfo9c77kZNWqUtmzZkuW0OnXqaM2aNfrss8/yrTAAAIDfI9fhpn79+qpfv3620+vUqaM6derkS1EAAAC/V759id+iRYtyDD8AAADXQp7CzQcffKCuXbuqR48e+vbbbyVJq1evVsOGDdWrVy81bdq0QIoEAADIrVyHmylTpujxxx/XgQMH9Pnnn6t169Z6+eWX1a1bN91///2Ki4vTe++9V5C1AgAAXFWuz7mJiorSjBkz1L9/f8XGxqp169ZavXq19u7dqzJlyhRgiQAAALmX6z03hw4dUps2bSRJrVq1kp+fn1566SWCDQAAuK7kOtxcvHhRAQEBnvv+/v6qUKFCgRQFAADwe+X6sJQkzZw5UyVKlJAkpaamas6cOSpfvrxXn2HDhuVfdQAAAHmU63BTrVo1ffDBB577lSpV0kcffeTVx+VyEW4AAEChynW4OXjwYAGWAQAAkD/y7Uv8AAAArgeEGwAA4CiEGwAA4CiEGwAA4CiEGwAA4Ch5Djc+Pj5KSEjI1J6UlCQfH598KQoAAOD3ynO4MbMs25OTk+Xv7/+HCwIAAPgjcv09N2+99Zaky1/U99tvKpaktLQ0rVu3TrVq1cr/CgEAAPIg1+HmjTfekHR5z82MGTO8DkH5+/srLCxMM2bMyP8KAQAA8iDX4ebAgQOSpMjISC1atEhly5YtsKIAAAB+rzyfc7NmzRqvYJOWlqbt27frxIkT+VoYAADA75HncDN8+HBFRUVJuhxs7r77bt12220KCQlRbGxsftcHAACQJ3kONwsWLFCDBg0kSUuXLtXBgwf1ww8/aPjw4RozZky+FwgAAJAXeQ43SUlJqlSpkiQpJiZGXbt2VY0aNTRgwADt2LEj3wsEAADIizyHm6CgIO3atUtpaWlatmyZ2rRpI0k6f/48X+IHAAAKXa6vlsrQr18/devWTcHBwXK5XGrbtq0k6dtvv+V7bgAAQKHLc7gZN26c6tatq8OHD6tr165yu92SLv8sw6hRo/K9QAAAgLzIc7iRpAcffFCSdPHiRU9bnz598qciAACAPyDP59ykpaVp4sSJqlKlikqUKKH9+/dLkl544QXPJeIAAACFJc/h5qWXXtKcOXP06quvev1QZr169TRz5sx8LQ4AACCv8hxuoqOj9f7776tnz55eV0fVr19fP/zwQ74WBwAAkFd5DjdHjhxR9erVM7Wnp6crJSUlX4oCAAD4vfIcburUqaP169dnal+wYIEaNmyYL0UBAAD8Xrm+Wqp///568803NXbsWD3yyCM6cuSI0tPTtWjRIu3Zs0fR0dH68ssvC7JWAACAq8r1npsPP/xQFy5c0H333af58+crJiZGLpdLL774onbv3q2lS5d6vtAPAACgsOR6z42Zef5u37692rdvXyAFAQAA/BF5OufG5XIVVB0AAAD5Ik/fUFyjRo2rBpxff/31DxUEAADwR+Qp3IwfP16lS5cuqFoAAAD+sDyFm4ceekgVK1YsqFoAAAD+sFyfc8P5NgAA4EaQ63Dz26ulAAAArle5PiyVnp5ekHUAAADkizz//AIAAMD1jHADAAAchXADAAAchXADAAAchXADAAAchXADAAAchXADAAAchXADAAAchXADAAAchXADAAAcpdDDzfTp0xUeHq6AgAA1atRI69evz9V8//rXv+Tr66tbb721YAsEAAA3lEINN/Pnz9fw4cM1ZswYbdu2TS1atFCHDh0UFxeX43ynTp1S7969dc8991yjSgEAwI2iUMPN1KlTNWDAAA0cOFARERGaNm2aQkJC9O677+Y432OPPaYePXqoadOm16hSAABwoyi0cHPp0iVt2bJF7dq182pv166dNmzYkO18s2fP1r59+zR27NhcjZOcnKzTp0973QAAgHMVWrhJTExUWlqagoKCvNqDgoIUHx+f5Tw//fSTRo0apblz58rX1zdX40yePFmlS5f23EJCQv5w7QAA4PpV6CcUu1wur/tmlqlNktLS0tSjRw+NHz9eNWrUyPXyR48erVOnTnluhw8f/sM1AwCA61fudn8UgPLly8vHxyfTXpqEhIRMe3Mk6cyZM9q8ebO2bdumJ554QpKUnp4uM5Ovr69WrFih1q1bZ5rP7XbL7XYXzIMAAADXnULbc+Pv769GjRpp5cqVXu0rV65Us2bNMvUvVaqUduzYoe3bt3tugwYNUs2aNbV9+3Y1adLkWpUOAACuY4W250aSRo4cqUceeUSNGzdW06ZN9f777ysuLk6DBg2SdPmQ0pEjRxQdHa0iRYqobt26XvNXrFhRAQEBmdoBAMCfV6GGm+7duyspKUkTJkzQsWPHVLduXcXExCg0NFSSdOzYsat+5w0AAMBvFWq4kaQhQ4ZoyJAhWU6bM2dOjvOOGzdO48aNy/+iAADADavQr5YCAADIT4QbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIQbAADgKIUebqZPn67w8HAFBASoUaNGWr9+fbZ9Fy1apLZt26pChQoqVaqUmjZtquXLl1/DagEAwPWuUMPN/PnzNXz4cI0ZM0bbtm1TixYt1KFDB8XFxWXZf926dWrbtq1iYmK0ZcsWRUZG6r777tO2bduuceUAAOB65VuYg0+dOlUDBgzQwIEDJUnTpk3T8uXL9e6772ry5MmZ+k+bNs3r/ssvv6zPP/9cS5cuVcOGDbMcIzk5WcnJyZ77p0+fzr8HAAAArjuFtufm0qVL2rJli9q1a+fV3q5dO23YsCFXy0hPT9eZM2dUrly5bPtMnjxZpUuX9txCQkL+UN0AAOD6VmjhJjExUWlpaQoKCvJqDwoKUnx8fK6W8frrr+vcuXPq1q1btn1Gjx6tU6dOeW6HDx/+Q3UDAIDrW6EelpIkl8vldd/MMrVlZd68eRo3bpw+//xzVaxYMdt+brdbbrf7D9cJAABuDIUWbsqXLy8fH59Me2kSEhIy7c250vz58zVgwAAtWLBAbdq0KcgyAQDADabQDkv5+/urUaNGWrlypVf7ypUr1axZs2znmzdvnvr27atPPvlEnTp1KugyAQDADaZQD0uNHDlSjzzyiBo3bqymTZvq/fffV1xcnAYNGiTp8vkyR44cUXR0tKTLwaZ379568803deedd3r2+hQtWlSlS5cutMcBAACuH4Uabrp3766kpCRNmDBBx44dU926dRUTE6PQ0FBJ0rFjx7y+8+a9995TamqqHn/8cT3++OOe9j59+mjOnDnXunwAAHAdKvQTiocMGaIhQ4ZkOe3KwBIbG1vwBQEAgBtaof/8AgAAQH4i3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEch3AAAAEcp9HAzffp0hYeHKyAgQI0aNdL69etz7L927Vo1atRIAQEBuummmzRjxoxrVCkAALgRFGq4mT9/voYPH64xY8Zo27ZtatGihTp06KC4uLgs+x84cEAdO3ZUixYttG3bNj3//PMaNmyYFi5ceI0rBwAA16tCDTdTp07VgAEDNHDgQEVERGjatGkKCQnRu+++m2X/GTNmqFq1apo2bZoiIiI0cOBA9e/fX1OmTLnGlQMAgOuVb2ENfOnSJW3ZskWjRo3yam/Xrp02bNiQ5TwbN25Uu3btvNrat2+vqKgopaSkyM/PL9M8ycnJSk5O9tw/deqUJOn06dN/9CFkcvbs2ctjxu9V+qWL+b584EaW8uvPki5vJwWx/V0rbOdAzgpqW89YlpldtW+hhZvExESlpaUpKCjIqz0oKEjx8fFZzhMfH59l/9TUVCUmJio4ODjTPJMnT9b48eMztYeEhPyB6nN2YvnfC2zZwI2uZcuWhV1CvmA7B3JWUNv6mTNnVLp06Rz7FFq4yeByubzum1mmtqv1z6o9w+jRozVy5EjP/fT0dP36668KDAzMcRzc+E6fPq2QkBAdPnxYpUqVKuxyABQQtvU/BzPTmTNnVLly5av2LbRwU758efn4+GTaS5OQkJBp70yGSpUqZdnf19dXgYGBWc7jdrvldru92sqUKfP7C8cNp1SpUrzgAX8CbOvOd7U9NhkK7YRif39/NWrUSCtXrvRqX7lypZo1a5blPE2bNs3Uf8WKFWrcuHGW59sAAIA/n0K9WmrkyJGaOXOmZs2apd27d2vEiBGKi4vToEGDJF0+pNS7d29P/0GDBunQoUMaOXKkdu/erVmzZikqKkpPP/10YT0EAABwnSnUc266d++upKQkTZgwQceOHVPdunUVExOj0NBQSdKxY8e8vvMmPDxcMTExGjFihN555x1VrlxZb731lh544IHCegi4jrndbo0dOzbTYUkAzsK2jiu5LDfXVAEAANwgCv3nFwAAAPIT4QYAADgK4QYAADgK4QYAADgK4QaSpFatWmn48OEFPs7Bgwflcrm0ffv2Ah8rv1yrdTNu3DjdeuutBT4O8GdzLV93wsLCNG3atAIfBzkj3PwJ9O3bV/fff/91MW5ISIjnsn9Jio2Nlcvl0smTJ/Nt3EcffVQ+Pj769NNP8zRfdrUsWrRIEydOzLf6pMs/F7JkyRKvtqefflqrVq3K13GAK/Xt21cul0sul0u+vr6qVq2aBg8erBMnTuRpOVk9h6Wcg8T999+vvn37XnXZFy5cUNmyZVWuXDlduHAhT3Xl5nUnP8yZMyfLb7vftGmTHn300XwbB78P4QbXlI+PjypVqiRf34L5iqXz589r/vz5euaZZxQVFZUvyyxXrpxKliyZL8vKSYkSJbL9GREgP/3lL3/RsWPHdPDgQc2cOVNLly7VkCFDCrssj4ULF6pu3bqqXbu2Fi1a9IeXV9CvO79VoUIFFStWrMDHQc4IN39C586dU+/evVWiRAkFBwfr9ddfz9Tn0qVLevbZZ1WlShUVL15cTZo0UWxsrGd6xqeW5cuXKyIiQiVKlPC8YEqXD7F8+OGH+vzzzz2fEmNjY70+1R08eFCRkZGSpLJly8rlcqlv376Kjo5WYGCgkpOTvWp64IEHvL6xOisLFixQ7dq1NXr0aP3rX//SwYMHvaYnJyfr2WefVUhIiNxut2655RZFRUVlW4vkfVhq9OjRuvPOOzONW79+fY0dO1bS5U9ubdu2Vfny5VW6dGm1bNlSW7du9fQNCwuTJHXp0kUul8tz/8rDUunp6ZowYYKqVq0qt9utW2+9VcuWLfNMz1iXixYtUmRkpIoVK6YGDRpo48aNOa4jwO12q1KlSqpataratWun7t27a8WKFV59Zs+erYiICAUEBKhWrVqaPn36NasvKipKvXr1Uq9evbL8kPL999+rU6dOKlWqlEqWLKkWLVpo3759uXrdSU9PV9WqVTVjxgyvZW7dulUul0v79++XJE2dOlX16tVT8eLFFRISoiFDhujs2bOSLu/l7devn06dOuUZZ9y4cZIyH5aKi4tT586dVaJECZUqVUrdunXTL7/84pmesd1/9NFHCgsLU+nSpfXQQw/pzJkz+bxW/2QMjtenTx/r3Lmz5/7gwYOtatWqtmLFCvvvf/9r9957r5UoUcKefPJJT58ePXpYs2bNbN26dbZ371577bXXzO12248//mhmZrNnzzY/Pz9r06aNbdq0ybZs2WIRERHWo0cPMzM7c+aMdevWzf7yl7/YsWPH7NixY5acnGwHDhwwSbZt2zZLTU21hQsXmiTbs2ePHTt2zE6ePGnnz5+30qVL2z/+8Q9PPcePHzd/f39bvXp1jo+1RYsW9ve//93MzB544AF78cUXvaZ369bNQkJCbNGiRbZv3z77+uuv7dNPP822FjOzli1betbNjh07TJLt3bvXs8ydO3d65jMzW7VqlX300Ue2a9cu27Vrlw0YMMCCgoLs9OnTZmaWkJBgkmz27Nl27NgxS0hIMDOzsWPHWoMGDTzLnTp1qpUqVcrmzZtnP/zwgz377LPm5+fn+R9krMtatWrZl19+aXv27LEHH3zQQkNDLSUlJcf1hD+vK18P9u3bZ7Vr17agoCBP2/vvv2/BwcG2cOFC279/vy1cuNDKlStnc+bM8fSRZIsXL860/N9u41fq3Lmz9enTJ8f69u7da26323799VdLSkoyt9tt+/bt80z/+eefrVy5cvbXv/7VNm3aZHv27LFZs2bZDz/8kKvXHTOzp556yu666y6vcZ966ilr2rSp5/4bb7xhq1evtv3799uqVausZs2aNnjwYDMzS05OtmnTplmpUqU845w5c8bMzEJDQ+2NN94wM7P09HRr2LCh3XXXXbZ582b797//bbfddpu1bNnSM87YsWOtRIkS9te//tV27Nhh69ats0qVKtnzzz+f43pCzgg3fwK/fTE7c+aM+fv726effuqZnpSUZEWLFvW8ge/du9dcLpcdOXLEazn33HOPjR492swuh5sr3+TfeecdrxfIK19EzTK/8K1Zs8Yk2YkTJ7z6DR482Dp06OC5P23aNLvpppssPT0928f5448/mp+fnx0/ftzMzBYvXmwhISGWlpZmZmZ79uwxSbZy5cos58+ult+GGzOz+vXr24QJEzz3R48ebbfffnu2daWmplrJkiVt6dKlnras3hiuDDeVK1e2l156yavP7bffbkOGDDGz/7cuZ86c6Zn+/fffmyTbvXt3tvXgz61Pnz7m4+NjxYsXt4CAAJNkkmzq1KmePiEhIfbJJ594zTdx4kSvN/+CCjfPP/+83X///V7zjBkzxnN/9OjRFh4ebpcuXcr28V3tdWfr1q3mcrns4MGDZmaWlpZmVapUsXfeeSfbuv7xj39YYGCg5/7s2bOtdOnSmfr9NtysWLHCfHx8LC4uzjM9Yxv97rvvzOzydl+sWDHPhx8zs2eeecaaNGmSbS24Og5L/cns27dPly5dUtOmTT1t5cqVU82aNT33t27dKjNTjRo1VKJECc9t7dq12rdvn6dfsWLFdPPNN3vuBwcHKyEhIV/q/Nvf/qYVK1boyJEjki7vIs84ETI7UVFRat++vcqXLy9J6tixo86dO6evv/5akrR9+3b5+PioZcuWf6i2nj17au7cuZIkM9O8efPUs2dPz/SEhAQNGjRINWrUUOnSpVW6dGmdPXvW63fSrub06dM6evSomjdv7tXevHlz7d6926utfv36nr+Dg4M9NQDZiYyM1Pbt2/Xtt99q6NChat++vYYOHSpJOn78uA4fPqwBAwZ4bf+TJk3y2v4LQlpamj788EP16tXL09arVy99+OGHSktLk3R5O27RooX8/Px+9zgNGzZUrVq1NG/ePEnS2rVrlZCQoG7dunn6rFmzRm3btlWVKlVUsmRJ9e7dW0lJSTp37lyux9m9e7dCQkIUEhLiaatdu7bKlCnjtR2HhYV5ndeXn6+lf1aF+sOZuPYsFz8llp6eLh8fH23ZskU+Pj5e00qUKOH5+8oXF5fLlavl50bDhg3VoEEDRUdHq3379tqxY4eWLl2abf+0tDRFR0crPj7e66TBtLQ0RUVFqV27dipatGi+1NajRw+NGjVKW7du1YULF3T48GE99NBDnul9+/bV8ePHNW3aNIWGhsrtdqtp06a6dOlSnse6MsyZWaa23/4fMqalp6fneSz8eRQvXlzVq1eXJL311luKjIzU+PHjNXHiRM9z54MPPlCTJk285rvy9SArpUuXliSdOnUq07STJ096fhg5K8uXL9eRI0fUvXt3r/a0tDStWLFCHTp0yLftuGfPnvrkk080atQoffLJJ14fjA4dOqSOHTtq0KBBmjhxosqVK6dvvvlGAwYMUEpKSq7HyGp7zao9q9dStuE/hj03fzLVq1eXn5+f/v3vf3vaTpw4oR9//NFzv2HDhkpLS1NCQoKqV6/udatUqVKux/L39/d82sqpj6Qs+w0cOFCzZ8/WrFmz1KZNG69PP1eKiYnRmTNntG3bNm3fvt1zW7BggZYsWaKkpCTVq1dP6enpWrt2bZ5r+a2qVavq7rvv1ty5czV37ly1adNGQUFBnunr16/XsGHD1LFjR9WpU0dut1uJiYley/Dz88txnFKlSqly5cr65ptvvNo3bNigiIiIHOsD8mrs2LGaMmWKjh49qqCgIFWpUkX79+/PtP2Hh4dfdVlly5ZVhQoVtGnTJq/2Cxcu6Pvvv/faS3ylqKgoPfTQQ17b8Pbt29WzZ0/PicX169fX+vXrsw0ZuXndkS5/SNmxY4e2bNmizz77zGvv6+bNm5WamqrXX39dd955p2rUqKGjR4/meZzatWsrLi5Ohw8f9rTt2rVLp06dYjsuYISbP5kSJUpowIABeuaZZ7Rq1Srt3LlTffv2VZEi/++pUKNGDfXs2VO9e/fWokWLdODAAW3atEmvvPKKYmJicj1WWFiY/vvf/2rPnj1KTEzM8sUoNDRULpdLX375pY4fP+65GkG6/MnqyJEj+uCDD9S/f/8cx4qKilKnTp3UoEED1a1b13N74IEHVKFCBX388ccKCwtTnz591L9/fy1ZskQHDhxQbGys/vGPf1y1liv17NlTn376qRYsWOC1C126HCA/+ugj7d69W99++6169uyZ6dNmWFiYVq1apfj4+Gy/X+SZZ57RK6+8ovnz52vPnj0aNWqUtm/frieffDLHdQHkVatWrVSnTh29/PLLki5fwTN58mS9+eab+vHHH7Vjxw7Nnj1bU6dO9ZrvwIEDmYLI2bNn9fTTT+vll1/WRx99pH379mnz5s3q3bu3fH19M20vGY4fP66lS5eqT58+Xttw3bp11adPH33xxRc6fvy4nnjiCZ0+fVoPPfSQNm/erJ9++kkfffSR9uzZIyl3rzuSFB4ermbNmmnAgAFKTU1V586dPdNuvvlmpaam6u2339b+/fv10UcfZbq6KiwsTGfPntWqVauUmJio8+fPZxqjTZs2ql+/vnr27KmtW7fqu+++U+/evdWyZUs1btw49/8g5F0hnu+Da+TKE+zOnDljvXr1smLFillQUJC9+uqrmU6avXTpkr344osWFhZmfn5+VqlSJevSpYv997//NbOsT6ZbvHix/fYplZCQYG3btrUSJUqYJFuzZk2WJxtOmDDBKlWqZC6XK9PJho888oiVK1fOLl68mO3ji4+PN19fX6+rq35r6NChVq9ePTMzu3Dhgo0YMcKCg4PN39/fqlevbrNmzcqxlivXjZnZiRMnzO12W7FixTxXSWTYunWrNW7c2Nxut91yyy22YMECr5MMzcy++OILq169uvn6+lpoaKiZZT6hOC0tzcaPH29VqlQxPz8/a9CggX311Vee6VmtyxMnTnjWNZCVrE64NTObO3eu+fv7e05+nTt3rt16663m7+9vZcuWtbvvvtsWLVrk6a///0TkK29r1qyxtLQ0e+edd6x+/fpWvHhxq1Klij3wwAP2008/ZVvXlClTrEyZMlmeKJySkmLlypWz119/3czM/vOf/1i7du2sWLFiVrJkSWvRooXniqrcvu6YXb4IQpL17t0705hTp0614OBgK1q0qLVv396io6MzXXAwaNAgCwwMNEk2duxYM7NM2/qhQ4fsf/7nf6x48eJWsmRJ69q1q8XHx3umX7ndm12+UivjdQG/j8ssn06SAApA27ZtFRERobfeequwSwEA3CAIN7gu/frrr1qxYoV69uypXbt25XicHgCA3+JqKVyXbrvtNp04cUKvvPIKwQYAkCfsuQEAAI7C1VIAAMBRCDcAAMBRCDcAAMBRCDcAAMBRCDcAAMBRCDcAAMBRCDcAAMBRCDcAAMBR/j9PQF1y5TyTZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(1,3),rms_list ,edgecolor = \"Black\")\n",
    "plt.xticks(np.arange(1,3))\n",
    "plt.title(\"Identity vs ReLU Activation for RMSE Score\")\n",
    "plt.ylabel(\"Test RMSE\")\n",
    "plt.xticks([1,2], [\"Identity Activation\", \"ReLU Activation\"])\n",
    "plt.show()\n",
    "      \n",
    "plt.bar(np.arange(1,3),r2_list, edgecolor = \"Black\")\n",
    "plt.xticks(np.arange(1,3))\n",
    "plt.title(\"Identity vs ReLU Activation for R2 Score\")\n",
    "plt.ylabel(\"Test R2\")\n",
    "plt.xticks([1,2], [\"Identity Activation\", \"ReLU Activation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa31b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
